from env.minesweeper_env import MinesweeperEnv
from agent.q_learning_agent import QLearningAgent
import numpy as np
import os

def create_action_space(width, height):
    """
    TÃ¼m (x, y) pozisyonlarÄ±nÄ± iÃ§eren aksiyon listesi Ã¼retir.
    """
    return [(x, y) for y in range(height) for x in range(width)]

def train_q_learning_agent(
        episodes=50000,
        width=4,
        height=4,
        n_mines=3,
        log_interval=100
    ):
    """
    Q-learning ajanÄ±nÄ± belirli sayÄ±da bÃ¶lÃ¼m (episode) boyunca Minesweeper ortamÄ±nda eÄŸitir.
    EÄŸitim boyunca Ã¶dÃ¼l, adÄ±m ve hamleler terminale loglanÄ±r.

    Parameters:
    - episodes: KaÃ§ oyun oynanacaÄŸÄ±
    - width, height: Oyun tahtasÄ± boyutu
    - n_mines: MayÄ±n sayÄ±sÄ±
    - log_interval: KaÃ§ bÃ¶lÃ¼mde bir detaylÄ± log ve render yapÄ±lacaÄŸÄ±
    """
    # Ortam ve aksiyon listesi oluÅŸtur
    env = MinesweeperEnv(width, height, n_mines)
    action_space = create_action_space(width, height)

    # Agent oluÅŸtur
    agent = QLearningAgent(
        state_shape=(height, width),
        action_space=action_space,
        learning_rate=0.1,
        discount=0.99,
        epsilon=1.0,
        epsilon_decay=0.995,
        epsilon_min=0.01
    )

    win_count = 0

    # EÄŸitim dÃ¶ngÃ¼sÃ¼
    for episode in range(1, episodes + 1):
        state = env.reset()
        done = False
        total_reward = 0
        steps = 0

        print(f"\nğŸ¯ Episode {episode} baÅŸlÄ±yor... [Epsilon: {agent.epsilon:.3f}]")

        while not done and steps < 100:
            action = agent.choose_action(state)
            next_state, reward, done, info = env.step(action)

            agent.learn(state, action, reward, next_state, done)

            state = next_state
            total_reward += reward
            steps += 1

            # Log: ilk birkaÃ§ bÃ¶lÃ¼mde ve log_interval ile belirlenen aralÄ±klarla
            if episode <= 5 or episode % log_interval == 0:
                print(f"  â¤ AdÄ±m {steps:02}: Aksiyon={action}, Ã–dÃ¼l={reward}, Mesaj='{info.get('msg', '')}'")
                env.render()
                
        if done and reward > 0:  # Ã–dÃ¼l pozitifse genelde kazanmÄ±ÅŸ demektir
            win_count += 1
                
        print(f"âœ… Episode {episode} bitti. Toplam Ã–dÃ¼l: {total_reward}, AdÄ±m SayÄ±sÄ±: {steps},  Toplam Kazanma SayÄ±sÄ±: {win_count}")

    # EÄŸitilen model kaydedilir (zaman damgalÄ± olarak)
    agent.save("models/q_learning")

if __name__ == "__main__":
    train_q_learning_agent()
